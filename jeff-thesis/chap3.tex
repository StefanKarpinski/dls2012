\chapter{Implementation}

\section{Method Dispatch}

Much of the implementation is organized around method dispatch. The dispatch
logic is both a large portion of the behavior of Julia functions, and the
entry point of the compiler's type inference and specialization logic.

\subsection{Method Caching and Specialization}

The first step of method dispatch is to look for the argument types in a
per-function cache. The cache has an entry for (almost) every set of concrete
types to which the function has been applied. Concrete types are hash-consed,
so they can be compared by simple pointer comparison. This makes cache lookup
faster than the $\subtype$ predicate. As part of hash-consing, concrete types
are assigned small integer IDs. The ID of the first argument is used as a
primary key into a method cache, so when signatures differ only in the
type of the first argument a simple indexed lookup suffices.

On a cache miss, a slower search for the matching definition is performed using
$\subtype$.
Then, type inference is invoked on the matching method using the types
of the actual arguments. The resulting type-annotated and optimized method is
stored in the cache. In this way, method dispatch is the primary source of type
information for the compiler.

\subsection{Method Specialization Heuristics}

Our aggressive use of code specialization has the obvious pitfall that it might
lead to excessive code generation, consuming memory and compile time. We found
that a few mild heuristics suffice to give a usable system with reasonable
resource requirements.

The first order of business is to ensure that the dispatch and specialization
process converges. The reason it might not is that our type inference algorithm
is implemented in Julia itself. Calling a method on a certain type $A$ can cause
the type inference code to call the same method on type $B$, where types
$A$ and $B$
follow an infinite ascending chain in either of two partial orders (the
$\typeof$ order or the $\subtype$ order). Singleton kinds are the most
prominent example, as type inference might attempt to successively consider
{\tt Int32}, {\tt Type\{Int32\}}, {\tt Type\{Type\{Int32\}\}}, and so on. We
stop this process by replacing any nestings of {\tt Type} with the
unspecialized version of {\tt Type} during method specialization (unless the
original method declaration actually specified a type like
{\tt Type\{Type\{Int32\}\}}).

The next heuristic avoids specializing methods for tuple types of every length.
Tuple types are cached as the intersection of the declared type of the method
slot with the generic tuple type {\tt (Any...)}. This makes the resulting cache
entry valid for any tuple argument, again unless the method declaration
contained a more specific tuple type. Note that all of these heuristics require
corresponding changes in the method cache lookup procedure, since they yield
cache entries that do not have to exactly match candidate arguments.

A similar heuristic is applied to variadic methods, where we wish to avoid
caching argument lists of every length. This is done by capping argument lists
at the length of the longest signature of any method in the same generic
function. The ``capping'' involves replacing the last argument with a
{\tt ...} type. Ideally, we want to form the biggest type that's not a
supertype of any other method signatures. However, this is not always possible
and the capped type might conflict with another signature. To deal with this
case, we find all non-empty intersections of the capped type with other
signatures, and add dummy cache entries for them. Hitting one of these entries
alerts the system that the arguments under consideration are not really in the
cache. Without the dummy entries, some arguments might incorrectly match the
capped type, causing the wrong method to be invoked.

The next heuristic concerns singleton kinds again. Because of the singleton
kind feature, every distinct type object ({\tt Any}, {\tt Number}, {\tt Int},
etc.) passed to a method might trigger a new specialization. However, most
methods are not ``class methods'' and are not concerned with type objects.
Therefore, if no method definition in a certain function involves {\tt Type}
for a certain argument slot, then that slot is not specialized for different
type objects.

Finally, we introduce a special type {\tt ANY} that can be used in a method
signature to hint that a slot should not be specialized. This is used in the
standard library in a small handful of places, and in practice is less
important than the heuristics described above.


\section{Type Inference}

Types of program expressions and variables are inferred by forward
dataflow analysis\footnote{Adding a reverse dataflow pass could potentially
improve type information, but we have not yet done this.}.
A key feature of this form of type inference is that variable types are
inferred at each use, since assignment is allowed to change the type of
a variable.
We determine a maximum fixed-point (MFP) solution using
Algorithm~\ref{alg1}, based on
Mohnen's graph-free dataflow analysis framework \cite{graphfree}. The basic
idea is to keep track of the state (the types of all variables) at each program
point, determine the effect of each statement on the state, and ensure that
type information from each statement eventually propagates to all other
statements reachable by control flow. We augment the basic algorithm with
support for mutually-recursive functions
(functions are treated as program points that might need to be revisited).

The origin of the type information used by the MFP algorithm is
evaluation of known functions over the type domain \cite{abstractinterp}.
This is done by the $\eval$ subroutine. The $\interpret$ subroutine calls
$\eval$, and also handles assignment statements by returning the new types
of affected variables. Each known function
call is either to one of the small number of built-in functions, in which
case the result type is computed by a (usually trivial) hand-written
type transfer function, or to a generic function, in which case the result
type is computed by recursively invoking type inference. In the generic
function case, the inferred argument types are met ($\sqcap$) with the
signatures of each method definition. Matching methods are those where the
meet (greatest lower bound)
is not equal to the bottom type ({\tt None} in Julia).
Type inference is invoked on each matching
method, and the results are joined ($\sqcup$) together. The following equation
summarizes this process:

\[
T(f,t_{arg}) = \bigsqcup_{(s,g) \in f}T(g,t_{arg} \sqcap s)
\]

\noindent
$T$ is the type inference function.
$t_{arg}$ is the inferred argument tuple type. The tuples $(s,g)$
represent the signatures $s$ and their associated definitions $g$ within
generic function $f$.

Two optimizations are helpful here. First, it is rarely
necessary to consider all method definitions. Since methods are stored in
sorted order, as soon as the union of the signatures considered so far is a
supertype of $t_{arg}$, no more definitions need to be considered.
Second, the join operator employs \emph{widening} \cite{widening}:
if a type becomes too large it may simply return {\tt Any}. In this case
the recursive inference process may stop immediately.

% \subsection{MFP Dataflow Algorithm}

\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}

\begin{algorithm}
\caption{Infer function return type}
\label{alg1}
\begin{algorithmic}
\REQUIRE function $F$, argument type tuple $A$, abstract execution stack $T$
\ENSURE result type $T.R$
\STATE $V \leftarrow$ set of all locally-bound names
\STATE $V_{a} \leftarrow$ argument names
\STATE $n \leftarrow \length(F)$
\STATE $W \leftarrow \{1\}$ \COMMENT {set of program counters}
\STATE $P_r \leftarrow \emptyset$ \COMMENT {statements that recur}
\STATE $\forall i, S[1,V[i]] \leftarrow \text{Undef}$
\STATE $\forall i, S[1,V_{a}[i]] \leftarrow A[i]$
\WHILE{$W \neq \emptyset$}
 \STATE $p \leftarrow \operatorname{choose}(W)$
 \REPEAT
  \STATE $W \leftarrow W - p$
  \STATE $new \leftarrow \interpret(F[p],S[p],T)$
  \IF {$T.rec$}
   \STATE $P_r \leftarrow P_r \cup \{p\}$
   \STATE $T.rec \leftarrow \text{false}$
  \ENDIF
  \STATE $p\prime \leftarrow p+1$
  \IF{$F[p] = $\texttt{(goto l)}}
   \STATE $p\prime \leftarrow l$
  \ELSIF{$F[p] = $\texttt{(gotoif cond l)}}
   \IF {\NOT $new \leq S[l]$}
    \STATE $W \leftarrow W \cup \{l\}$
    \STATE $S[l] \leftarrow S[l] \sqcup new$
   \ENDIF
  \ELSIF{$F[p] = $\texttt{(return e)}}
   \STATE $p\prime \leftarrow n+1$
   \STATE $r \leftarrow \eval(e,S[p],T)$
   \IF {\NOT $r \leq T.R$}
    \STATE $T.R \leftarrow T.R \sqcup r$
    \STATE $W \leftarrow W \cup P_r$
   \ENDIF
  \ENDIF
  \IF{$p\prime \leq n$ \AND \NOT $new \leq S[p\prime]$}
   \STATE $S[p\prime] \leftarrow S[p\prime] \sqcup new$
   \STATE $p \leftarrow p\prime$
  \ENDIF
 \UNTIL{$p\prime = n+1$}
\ENDWHILE
\STATE {$T.rec \leftarrow P_r \neq \emptyset$}
\end{algorithmic}
\end{algorithm}

\subsection{Interprocedural Type Inference}

Type inference is invoked through ``driver'' Algorithm~\ref{alg2}
which manages mutual recursion and memoization of inference results.
A stack of abstract activation records is maintained and used to detect
recursion. Each function has a property $\incomplete(F,A)$ indicating that
it needs to be revisited when new information is discovered about the
result types of functions it calls. The $\incomplete$ flags collectively
represent a set analogous to $W$ in Algorithm~\ref{alg1}.

The outer loop in Algorithm~\ref{alg2} looks for an existing activation
record for its input function and argument types. If one is found, it
marks all records from that point to the top of the stack, identifying
all functions involved in the call cycle. These marks
are discovered in Algorithm~\ref{alg1} when $\interpret$ returns, and all
affected functions are considered $\incomplete$. Algorithm~\ref{alg2}
continues to re-run inference on incomplete functions, updating the
inferred result type, until no recursion occurs or the result type
converges.

\begin{algorithm}
\caption{Interprocedural type inference}
\label{alg2}
\begin{algorithmic}
\REQUIRE function $F$, argument type tuple $A$, abstract execution stack $S$
\ENSURE returned result type
\STATE $R \leftarrow \bot$
\IF {$\recall(F,A)$ exists}
 \STATE $R \leftarrow \recall(F,A)$
 \IF {\NOT $\incomplete(F,A)$}
  \RETURN $R$
 \ENDIF
\ENDIF
\STATE $f \leftarrow S$
\WHILE {\NOT $\operatorname{empty}(f)$}
 \IF {$f.F$ is $F$ \AND $f.A=A$}
  \STATE $r \leftarrow S$
  \WHILE {\NOT $r=\tail(f)$}
   \STATE $r.rec \leftarrow \text{true}$
   \STATE $r \leftarrow \tail(r)$
  \ENDWHILE
  \RETURN $f.R$
 \ENDIF
 \STATE $f \leftarrow \tail(f)$
\ENDWHILE
\STATE $T \leftarrow \extend(S, \Frame(F=F,A=A,R=R,rec=\text{false}))$
\STATE invoke Algorithm~\ref{alg1} on $F,A,T$
\STATE $\recall(F,A) \leftarrow T.R$
\STATE $\incomplete(F,A) \leftarrow (T.rec \land \neg(R=T.R))$
\RETURN $T.R$
\end{algorithmic}
\end{algorithm}

Because this algorithm approximates run-time behavior, we are free to
change it without affecting the behavior of user programs --- except
that they might run faster. One valuable improvement is
to attempt full evaluation of branch conditions, and remove branches
with constant conditions.

%\subsection{Type Transfer Functions}

%todo ?

\section{Lattice Operations}

Our type lattice is complicated by the presence of type parameters, unions,
and diagonal type constraints in method signatures. Fortunately, for our
purposes only the $\leq$ ($\subtype$) relation needs to be computed accurately,
as it bears final responsibility for whether a method is applicable to
given arguments. Type union and intersection, used to estimate
least upper bounds and greatest lower bounds, respectively, may both be
conservatively approximated. If their results are too coarse, the
worst that can happen is performing method dispatch or type checks
at run time, since the inference process will simply conclude that it does
not know precise types.

A complication arises from the fact that our abstract domain is
available in a first-class fashion to user programs. When a program
contains a type-valued expression, we want to know which type it will
evaluate to, but this is not possible in general. Therefore in addition
to the usual \emph{type imprecision} (not knowing the type of a value),
we must also model \emph{type uncertainty}, where a type itself is
known imprecisely. A common example is application of the {\tt typeof}
primitive to a value of imprecise type. What is the abstract result of
{\tt typeof(x::Number)}? We handle this with a special type kind that
represents a \emph{range} rather than a point within the type lattice.
These kinds are essentially the type variables used in bounded
polymorphism \cite{boundedquant}. In this example, the
transfer function for {\tt typeof} is allowed to return
{\tt Type\{T<:Number\}}, where {\tt T} is a new type variable.


\subsection{Subtype Predicate}

See Algorithm~\ref{alg3}. Note that extensional type equality can be
computed as $(A\leq~B\land~B\leq~A)$, and this is used for types in
invariant context (i.e. type parameters). The algorithm uses subroutines
$\p(A)$ which gives the parameters of type $A$, and $\super(A)$ which gives
the declared supertype of $A$.

\begin{algorithm}
\caption{Subtype}
\label{alg3}
\begin{algorithmic}
\REQUIRE types $A$ and $B$
\ENSURE $A \leq B$
\IF {$A$ is a tuple type}
 \IF {$B$ is not a tuple type}
  \RETURN false
 \ENDIF
 \FOR {$i=1$ \TO $\length(A)$}
  \IF {$A[i]$ is $T...$}
   \IF {$\last(B)$ exists and is not $S...$}
    \RETURN false
   \ENDIF
   \RETURN $\subtype(T,B[j])), i \leq j \leq \length(B)$
  \ELSIF {$i > \length(B)$ \OR \NOT $\subtype(A[i],B[i])$}
   \RETURN false
  \ELSIF {$B[i]$ is $T...$}
   \RETURN $\subtype(A[j],T)), i < j \leq \length(A)$
  \ENDIF
 \ENDFOR
\ELSIF {$A$ is a union type}
 \RETURN $\forall t \in A, \subtype(t,B)$
\ELSIF {$B$ is a union type}
 \RETURN $\exists t \in B, \subtype(A,t)$
\ENDIF
\WHILE {$A \neq \texttt{Any}$}
 \IF {$\typename(A) = \typename(B)$}
  \RETURN {$\subtype(\p(A),\p(B)) \land \subtype(\p(B),\p(A))$}
 \ENDIF
 \STATE $A \leftarrow \super(A)$
\ENDWHILE
\IF {$A$ is of the form {\tt Type\{T\}}}
 \RETURN $\subtype(\typeof(\p(A)[1]),B)$
\ELSIF {$B$ is of the form {\tt Type\{T\}}}
 \STATE $B \leftarrow \p(B)[1]$
 \RETURN $\subtype(A,B) \land \subtype(B,A)$
\ENDIF
\RETURN $B = \texttt{Any}$
\end{algorithmic}
\end{algorithm}


\subsection{Type Union}

Since our type system explicitly supports unions, the union of $T$ and
$S$ can be computed simply by constructing the type {\tt Union(T,S)}.
An obvious simplification is performed: if one of $T$ or $S$ is a
subtype of the other, it can be removed from the union. Nested union
types are flattened, followed by pairwise simplification.

\subsection{Type Intersection}

This is the difficult one: given types $T$ and $S$, we must try to compute
the smallest type $R$ such that
$\forall s, s \in T \land s \in S \Rightarrow s \in R$.
The conservative solution is to give up on finding the smallest such type, and
return \emph{some} type with this property. Simply returning $T$ or $S$
suffices for correctness, but in practice this algorithm
makes the type inference process nearly useless. A slightly better
algorithm is to check whether one argument is a subtype of the other, and
return the smaller type. It is also possible to determine quickly, in
many cases, that two types are disjoint, and return $\bot$. With these
two enhancements we start to obtain some useful type information. However,
we need to do much better to take full advantage of the framework set up
so far.

Our algorithm has two phases. First, the structures of the two input types
are analyzed in a manner similar to $\subtype$, except a constraint
environment is built, with entries $T\leq S$ for type variables $T$ in
covariant contexts (tuples) and entries $T=S$ for type variables $T$ in
invariant contexts (type parameters). In the second phase the constraints
are solved with an algorithm (Algorithm~\ref{alg5}) similar to that
used by traditional polymorphic type systems \cite{MLtypeinf}.

The code for handling tuples and union types is similar to that in
Algorithm~\ref{alg3}, so we focus instead on intersecting types in the
nominative hierarchy (Algorithm~\ref{alg4}). The base case occurs when
the input types are from the same family, i.e. have the same
$\typename$. All we need to do is visit each parameter to collect any
needed constraints, and otherwise check that the parameters are equal.
When a parameter is a type variable, it is effectively covariant, and
must be intersected with the corresponding parameter of the other type
to form the final result.

\begin{algorithm}
\caption{Intersection of nominative types}
\label{alg4}
\begin{algorithmic}
\REQUIRE types $A$ and $B$, current constraint environment
\ENSURE return $T$ such that $A \sqcap B \leq T$, updated environment
\IF {$\typename(A) = \typename(B)$}
 \STATE $pa \leftarrow \operatorname{copy}(\p(A))$
 \FOR {$i=1$ \TO $\length(\p(A))$ }
  \IF {$\p(A)[i]$ is a typevar}
   \STATE {add $(\p(A)[i]=\p(B)[i])$ to constraints}
  \ELSIF {$\p(B)[i]$ is a typevar}
   \STATE {add $(\p(B)[i]=\p(A)[i])$ to constraints}
  \ENDIF
  \STATE $pa[i] \leftarrow \intersect(\p(A)[i],\p(B)[i])$
 \ENDFOR
 \RETURN {$\typename(A)\{pa...\}$}
\ELSE
 \STATE $sup \leftarrow \intersect(\super(A),B)$
 \IF {$sup = \bot$}
  \STATE $sup \leftarrow \intersect(A,\super(B))$
  \IF {$sup = \bot$}
   \RETURN $\bot$
  \ELSE
   \STATE $sub \leftarrow B$
  \ENDIF
 \ELSE
  \STATE $sub \leftarrow A$
 \ENDIF
 \STATE $E \leftarrow \conform(sup, \superdecl(sub))$
 \IF {$E$ contains parameters not in $\formals(sub)$}
  \RETURN $\bot$
 \ENDIF
 \RETURN $\intersect(sub, \typename(sub)\{E...\})$
\ENDIF
%\FORALL {$(S=U) \in E$}
% \STATE {$V \leftarrow $ value of $S$ in $sub$}
% \STATE {replace $U$ with $intersect(U,V)$}
%\ENDFOR
%\RETURN {instantiate $sub$ with $E$}
\end{algorithmic}
\end{algorithm}

\begin{algorithm}
\caption{Solve type variable constraints}
\label{alg5}
\begin{algorithmic}
\REQUIRE environment $X$ of pairs $T\leq S$ and $T=S$
\ENSURE environment $Y$ of unique variable assignments $T=S$, or failure
\STATE $Y \leftarrow \emptyset$
\STATE replace $(T\leq S) \in X$ with $(T=S)$ when $S$ is concrete
\FORALL {$(T=S) \in X$}
 \IF {$(T=R) \in X$ \AND $S\neq R$}
  \RETURN failure
 \ENDIF
\ENDFOR
\FORALL {$(T\leq S) \in X$}
 \IF {$(T=U) \in X$}
  \IF {\NOT $\find(X,U)\leq S$}
   \RETURN failure
  \ELSE
   \STATE $X \leftarrow X - (T\leq S)$
  \ENDIF
 \ELSIF {$(T\leq U) \in X$ and $U$ not a variable}
  \STATE replace $U$ with $U\sqcap^{*}S$
  \STATE $X \leftarrow X - (T\leq S)$
 \ENDIF
\ENDFOR
\FORALL {variables $T$}
 \IF {$(T=U) \in X$}
  \STATE $Y \leftarrow Y \cup \{T=U\}$
 \ELSE
  \STATE $S \leftarrow \bigsqcap^{*}_{} \find(X,U), \forall (T\leq U) \in X$
  \IF {$S = \bot$}
   \RETURN failure
  \ENDIF
  \STATE $Y \leftarrow Y \cup \{T=S\}$
 \ENDIF
\ENDFOR
\end{algorithmic}
\end{algorithm}

When the argument types are not from the same family, we recur up the
type hierarchy to see if any supertype of one of the arguments matches
the other. If so, the recursion gives us the intersected supertype $sup$,
and we face the problem of mapping it to the family of the original argument
type. To do this, we first call subroutine $\conform$, which takes two types
with the same structure and returns an environment $E$ mapping any
type variables in one to their corresponding components in the other.
$\superdecl(t)$ returns the type template used by $t$ to instantiate its
supertype. If all goes well, this tells us what parameters $sub$ would
have to be instantiated with to have supertype $sup$. If, however, $E$
contains type variables not controlled by $sub$, then there is no way
a type like $sub$ could have the required supertype, and the overall answer
is $\bot$.
Finally, we apply the base case to intersect $sub$ with the type obtained
by instantiating its family with parameter values in $E$.

Constraints $T\leq S$ where $S$ is a concrete type are converted to
$T=S$ to help sharpen the result type.
If Algorithm~\ref{alg5} identifies any conflicting constraints, the
type intersection is empty. If each type variable has exactly one
constraint $T=U$, we can simply substitute $\find(X,U)$ for each occurrence
of $T$ in the computed type intersection, and we have a final answer.
$\find$ works in the \emph{union-find} sense, following chains of equalities
until we hit a non-variable or an unconstrained variable. Unconstrained
type variables may be left in place.

The remaining case is type variables with multiple constraints. Finding
a satisfying assignment requires intersecting all the upper bounds for
a variable. It is here that we choose to throw in the towel and switch
to a coarser notion of intersection, denoted by $\sqcap^{*}$.
Intersection is effectively the inner loop of type inference, so in the
interest of getting a reasonable answer quickly we might pick
$X\sqcap^{*}Y=X$. A few simple heuristics might as well be added; for
example cases like two non-parameterized types where one is an immediate
subtype of the other can be supported easily.

In our implementation, type intersection handles most of the
complexity surrounding type variables and parametric methods. 
It is used to test applicability of parametric methods; since all
run-time argument lists are of concrete type, intersecting their types
with method signatures behaves like $\subtype$, except static parameters
are also properly matched. If intersection returns $\bot$ or does not find
values for all static parameters for a method, the method is not applicable.
Therefore in practice we do not really have the freedom to implement
$\sqcap$ and $\sqcap^{*}$ any way that obeys our correctness property.
They must be at least as accurate as $\subtype$ in the case where one
argument is concrete.


\subsection{Widening Operators}

Lattices used in practical program analyses often fail to obey the finite
chain condition necessary for the MFP algorithm to converge (i.e. they
are not of finite height) and ours is no exception.

Widening is applied in two places: by the join operator, and on every
recursive invocation of type inference.
When a union type becomes too large (as determined by an arbitrarily-chosen
cutoff), it is replaced with {\tt Any}. Tuple types lend themselves
to two infinite chains: one in depth ({\tt (Any,)}, {\tt ((Any,),)},
{\tt (((Any,),),)}, etc.) and one in length ({\tt (Any...,)},
{\tt (Any,Any...,)}, {\tt (Any,Any,Any...,)}, etc.). These chains are
capped at arbitrary cutoffs each time the inference process needs to
construct a tuple type.


%\subsection{Method Specificity Comparison}


\section{Code Generation and Optimization}

After type inference is complete, we annotate each expression with its
inferred type. We then run two symbolic optimization passes.
If the inferred argument types in a method call
indicate that a single method matches, we are free to inline that method.
For methods that return multiple values, inlining often yields
expressions that construct tuples and immediately take them apart. The
next optimization pass identifies these cases and removes the tuple
allocations.

The next set of optimizations is applied during code generation.
Our code generator targets the LLVM compiler framework \cite{LLVM}.
First, we examine uses of variables and assign local variables specific
scalar types where possible (LLVM uses a typed code representation).
The {\tt box} operations used to tag bit strings with types are done
lazily; they add a compile-time tag that causes generation of the
appropriate allocation code only when the value in question hits a context
that requires it (for example, assignment to an untyped data structure,
or being passed to an unknown function).

The code generator recognizes calls to key built-in and intrinsic functions,
and replaces them with efficient in-line code where possible. For example,
the {\tt is} function yields a pointer comparison, and {\tt typeof} might
yield a constant pointer value if the type of its argument is known.
Calls known to match single methods generate code to call the correct
method directly, skipping the dispatch process.

Finally, we run several of the optimization passes provided by LLVM.
This gives us all of the standard scalar optimizations, such as
strength reduction, dead code elimination, jump threading, and constant
folding. When
we are able to generate well-typed but messy code, LLVM gets us the
rest of the way to competitive performance. We have found that care
is needed in benchmarking: if the value computed by a loop is not
used, in some cases LLVM has been able to delete the whole thing.

%compile-time method lookup
%ccall intrinsic

% todo ?
% \section{Run Time System}

% lazy allocation of tuple types
% storing compiler data serialized
% 
